@echo off
echo ğŸš€ Starting Open LLM Orchestrator stack...

docker compose up -d

echo â³ Waiting for Ollama to be ready...

:waitloop
docker exec olo-ollama ollama list >nul 2>&1
if %errorlevel% neq 0 (
    timeout /t 2 >nul
    goto waitloop
)

echo ğŸ“¦ Pulling Mistral model (first run only)...
docker exec olo-ollama ollama pull mistral

echo.
echo âœ… Stack is ready!
echo.
echo ğŸŒ Chat UI      : http://localhost:3000
echo ğŸ§  Temporal UI  : http://localhost:8233
echo âš™ï¸  Control API : http://localhost:8080
pause
